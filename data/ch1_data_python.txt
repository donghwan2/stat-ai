ch1_데이터 분석과 파이썬 이해


page5. 데이터의 가치
안녕하세요, 여러분! 데이터에 대해 이야기할 때 종종 '금광이다, 석유다'라는 말을 듣죠? 이게 무슨 말인가 싶겠지만, 이 비유에는 분명한 이유가 있어요. 데이터에는 정말 무궁무진한 잠재력이 숨어 있거든요. 우리 주변에 널려 있는 데이터, 이게 바로 우리의 모든 결정에 영향을 미치는 그 무엇이랍니다.
근데, 잠깐만요. 원시 데이터 그 자체로는 마치 아무도 캐지 않은 금광 같아요. 그냥 숫자와 사실들이 의미 없이 뒤섞여 있죠. 그 금광에서 금을 캐내려면, 원시 데이터를 가공해야 해요. 그래야 정보라는 금덩이를 얻을 수 있죠.
정보란, 바로 가공되고 분석되어 의미를 갖게 된 데이터예요. 마치 원유를 정제해서 자동차를 움직이는 가솔린으로 만드는 것처럼요. 갑자기, 새로운 매장을 어디에 열지, 어떤 제품을 개발할지, 서비스를 어떻게 개선할지 결정하는 데 사용할 수 있게 되죠.
거기서 그치지 않아요. 그 정보를 시간에 걸쳐 조직하고, 경험과 맥락을 더하면 지식이 되죠. 지식이라는 건, 숨겨진 보물을 찾는 지도와 같아서, 어디를 파야 할지, 얼마나 깊이 파야 할지, 무슨 도구를 사용해야 할지 알려주는 거예요.
그리고 지식, 이게 끝이 아니에요. 계속해서 그 지식을 적용하고, 성공과 실패에서 배우면, 결국에는 지혜에 이르게 돼요. 지혜란, 무엇을 해야 하는지만 아는 게 아니라, 데이터를 통해 축적된 지식을 바탕으로 왜 그래야 하는지 이해하는 거죠.
다음 3일 동안 우리는 함께 이 보물 찾기 여정에 나설 거예요. 데이터 속에 숨겨진 가능성을 탐험하고, 데이터를 정보로 가공하는 방법을 배우며, 그 정보를 지식으로 체계화하는 과정을 시작하고, 더 나아가 똑똑한 결정을 내리는 지혜로 나아가는 여정이죠.
자 그럼, 모험을 시작해 보겠습니다.

page6. 요리와 닮은 데이터 분석 과정
여러분, 안녕하세요! 오늘은 데이터 분석을 요리에 비유해서 풀어볼 건데요. 왜냐하면, 데이터 분석이란 것도 사실은 일종의 요리 과정과 다를 바 없거든요.
자, 상상해 보세요. 마치 백종원 쉐프가 우삼겹 된장찌개를 끓이는 것처럼 말이죠. 먼저 쉐프는 마트에 가서 호박, 오이, 당근 등 다채로운 재료들을 골라와야 하잖아요? 데이터 분석에서도 이와 마찬가지로, 우리는 다양한 데이터를 수집합니다. 이 데이터들이 바로 요리의 '재료'가 되는 거죠.
수집한 재료는 어디에 보관하겠어요? 냉장고죠. 데이터 분석에서는 데이터베이스나 데이터 마트가 바로 그 냉장고와 같아요. 우리는 CSV라는 형태로 데이터를 '저장'해 둡니다.
그 다음엔 재료를 '손질'해야죠. 깨끗이 씻고, 적당한 크기로 썰어야 하고요. 데이터 분석에서는 이것이 '추출'과 '전처리'에 해당해요. 오늘은 이미 전처리가 완료된 데이터를 사용하니 이 단계는 넘어가도록 하죠.
이제 본격적으로 '조리'에 들어갑니다. 데이터 분석에서는 이게 바로 '분석' 단계예요. 집계, 시각화, 검정, 예측 등의 다양한 통계적 기법들로 이 데이터들을 요리해볼 겁니다.
마지막으로, 이렇게 분석해낸 내용을 '음식'으로 완성시키죠. 데이터 분석에서는 이게 리포트나 모형이 되어서, 커뮤니케이션에 쓸 수 있게 됩니다. 이게 바로 데이터 분석의 '마무리'랍니다.
자, 그럼 이제부터 이 모든 과정을 하나하나 차근차근 살펴보도록 하겠습니다. 요리를 하러 가시죠, 데이터 요리사 여러분!

page7. 형태와 시점에 따른 데이터의 분류
자, 이번에는 데이터의 여러 가지 다양한 형태에 대해서 이야기해볼 건데요, 우리 생활 곳곳에 존재하는 데이터들이 어떤 모습들로 우리 앞에 나타나는지 함께 살펴보죠.
먼저 '정형 데이터'란 것부터 볼까요? 엑셀이나 CSV 파일 생각하시면 되는데요, 이게 바로 구조화된 데이터입니다. 테이블 모양으로, 쉽게 말해 칸칸이 잘 정렬된 데이터죠. 이런 걸 tabular data, 즉 표 형태 데이터라고도 해요. 저희 수업에서는 주로 CSV 형식의 정형 데이터를 다룰 예정이에요.
그런데 모든 데이터가 그렇게 잘 정돈된 건 아니에요. 우리는 다루지는 않을 데이터긴 하지만 '비정형 데이터'라고 해서, 글이나 사진처럼 일정한 형식이 없는 데이터들도 있거든요. 2000년 인터넷이 보급되고 2000년대 후반부터 스마트폰이 보편화되면서부터 이런 비정형 데이터의 양이 엄청나게 늘었어요. SNS나 리뷰들, 어마어마하죠? 이런 걸 다루는데 아주 좋은 기술이 '딥러닝'이죠.
다음으로 '시계열 데이터'입니다. 시간에 따라 변화하는 데이터인데, 주식 시세를 떠올리시면 돼요. 시간이 흘러가면서 가격이 어떻게 변하는지, 이걸 라인 그래프로 그려볼 수 있죠.
그리고 그 반대되는 개념이 '종단 데이터'인데요, 특정 시점에서 주가에 영향을 미치는 다양한 요소들을 한 번에 모아본 데이터를 말해요.
이렇게 데이터는 그 형태나 수집된 시점에 따라 다양한 이름으로 불리게 되는데, 우리가 주로 다룰 데이터는 정형 데이터와 종단 데이터가 될 겁니다. 그럼, 이제 이 다양한 데이터들을 어떻게 활용하고 분석하는지, 차근차근 배워보도록 하겠습니다. 

page8. 데이터 분석의 목적
정보는 2가지 측면에서 살펴볼 수 있습니다. 먼저 데이터가 주어졌을 때 현재 상황을 인식하는 목적으로 데이터를 축약한다면 이것은 정보의 인식 파트가 되겠습니다. 대표적인 평균, 분산, 합계 등이죠. 그런데 단순 현황 파악을 넘어서서 분석이나 모델링 등으로 미래 예측이나 인사이트를 도출하고자 한다면 이것은 정보의 고도화라 부를 수 있습니다. chapter 3에서 배울 검정이나 chapter 4에서 배울 회귀분석이 대표적인 고도화 기법들이라 볼 수 있겠습니다. 이처럼 데이터에서 의미 있는 차이나 관계, 패턴 등을 파악하는 과정이 통계 기반의 데이터 분석이라고 할 수 있겠습니다.

page10. Python 분석 환경 설정
우리는 Python을 사용할 예정입니다.
그 이유는 Python은 데이터 집계와 시각화 뿐만 아니라 알고리즘으로 활용도 가능하기 때문입니다.
파이썬 코딩을 위해서는 Jupyter Notebook이라는 툴을 사용할 예정인데요, 이것은 아나콘다라는 프로그램을 설치하면 그 안에 들어있습니다. 그래서 사전에 아나콘다 설치를 요청드린 것이었습니다. 이 Jupyter notebook의 장점은 Line by line 으로 코딩을 하기 때문에 중간 과정 확인에 용이합니다. 그래서 데이터 분석이나 AI에서 많이 활용되고 있습니다.
아나콘다 설치가 안 되신 분들께서는 아나콘다 설치를 진행해주시고요, 
혹시라도 설치 과정에서 에러가 나거나 설치를 했는데도 Jupyter Notebook을 사용하는데 에러가 난다면 대체품으로 구글 콜랩을 안내드릴 예정입니다.
구글 콜랩은 Jupyter notebook과 형태와 사용방법이 거의 비슷하므로 이것을 사용하셔도 무방합니다.

page11. 쥬피터 노트북 단축키
쥬피터 노트북 단축키는 11 page에 정리되어 있으니 참고해주시기 바랍니다.
자 이제 그럼 실습코드 1번을 열어주시고 같이 통계를 위한 파이썬 기초 실습을 해보겠습니다.

page12. 라이브러리 설치 및 관리
pip라는 명령어는 라이브러리를 설치하는 명령어입니다. 
pip install 라이브러리명 이렇게 써주시면 원하는 라이브러리를 설치할 수 있습니다.
라이브러리 제거 명령어는 pip uninstall 라이브러리명 입니다.

page13. 라이브러리 불러오기
라이브러리가 설치된 상태라면 import 명령어로 불러올 수 있습니다.
여기서 as 는 alias, 한국말로 별칭의 줄임말로 특정 라이브러리 이름을 줄여서 부르겠다는 뜻입니다.

page14. 파이썬의 데이터 타입은 수치형과 문자열이 있습니다.
수치형 중 1과 같은 정수형은 int라고 하고, 3.14와 같은 실수형은 float라고 부릅니다.
이러한 수치형 데이터는 사칙연산 등의 연산이 가능합니다.
그리고 따옴표로 감싸면 문자열이라고 합니다. "삼성전자"와 같이 따옴표를 이용하면 문자를 표현할 수 있습니다.
홑따옴표와 쌍따옴표는 크게 상관 없습니다. 그리고 이러한 문자열은 + 를 이용해 결합도 가능합니다.

page15. 할당과 출력
변수라는 것이 존재하는데, 특정 값을 저장할 수 있습니다.
a=10 이라고 입력하면 a라는 변수에는 10이 저장되었습니다.
앞으로 a를 이용하면 10이라는 숫자를 이용하는 것과 같습니다.
그리고 print 함수를 이용하면 궁금한 변수나 결과값들을 출력해볼 수 있습니다.

page16. 리스트
리스트는 파이썬의 대표적인 데이터 바구니입니다. 
대괄호 []나 list()를 활용하여 리스트(list)를 생성 가능합니다.
append() 함수를 활용하면 요소 추가도 가능합니다. 반대로 pop() 함수를 이용하면 요소 삭제도 가능합니다.

page17. index와 슬라이스
대괄호 []를 활용하여 생성된 리스트 등에서 일부 선택이 가능합니다.
더해서 콜론 :을 활용하면 연속적인 일정 범위의 값 선택이 가능합니다. 이것을 슬라이싱(slicing)이라고도 부릅니다.

page18. pandas의 활용
Pandas 라이브러리의 read_csv() 함수를 사용해서 csv 데이터를 읽을 수 있습니다.
그러면 행, 열로 구성된 데이터프레임(dataframe) 형태가 됩니다. 2차원 형태입니다.
데이터프레임에서 특정 열 하나만 선택하면 시리즈(Series) 형태가 됩니다. 

page19. csv 파일 불러오기
데이터프레임(df)을 살펴보는 여러가지 파이썬 함수들이 존재합니다.
df.shape # 관측치, 변수 개수 확인
df.head(n=) # 앞 n개 관측치 확인
df.columns # 변수 이름 목록 확인
df.dtypes # 변수 형식 확인

page20. 조건 일치 관측치 선택
조건문을 이용해서 데이터프레임 중 특정 조건을 만족하는 데이터만 추출할 수도 있습니다.
df[조건] 공식을 이용하면 내가 원하는 조건에 맞는 데이터를 추출할 수 있습니다.
조건이 2개 이상인 경우, and 조건이면 &, or 조건이면 |를 이용해서 조건들을 여러개 연결할 수도 있습니다.












